
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/compare_classifiers.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_compare_classifiers.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_compare_classifiers.py:


============================
Nominal classifiers comparison
============================

Compare scikit compatible classifiers available in sklearn_nominal

.. GENERATED FROM PYTHON SOURCE LINES 8-65

.. code-block:: Python


    import pandas as pd
    from sklearn.metrics import accuracy_score

    from sklearn_nominal import (
        CN2Classifier,
        NaiveBayesClassifier,
        OneRClassifier,
        PRISMClassifier,
        TreeClassifier,
        ZeroRClassifier,
    )


    def read_classification_dataset(url: str):
        df = pd.read_csv(url)
        x = df.iloc[:, :-1]
        y = df.iloc[:, -1]
        return x, y, y.unique()


    dataset_name = "golf_classification"
    url_base = (
        "https://raw.githubusercontent.com/facundoq/facundoq.github.io/refs/heads/master/"
    )
    url = url_base + "datasets/classification/golf_classification_numeric.csv"
    x, y, class_names = read_classification_dataset(url)

    models = [
        TreeClassifier(),
        TreeClassifier(criterion="gini"),
        TreeClassifier(criterion="gain_ratio"),
        PRISMClassifier(min_rule_support=1),
        CN2Classifier(min_rule_support=1),
        OneRClassifier(),
        ZeroRClassifier(),
        NaiveBayesClassifier(),
    ]
    results = []
    for model in models:
        model.fit(x, y)
        y_pred = model.predict(x)
        score = accuracy_score(y, y_pred)

        print("===" * 20)
        print(f"Model {model}")
        print(model.pretty_print(class_names))
        print("---" * 20)
        print(f"Accuracy: {score:.3f}")
        print("===" * 20)
        print()
        result = {"model": str(model), "accuracy": score, "complexity": model.complexity()}
        results.append(result)

    results_df = pd.DataFrame.from_records(results)
    results_df.to_csv("doc/classifier_comparison.csv", float_format="%4g")
    print(results_df.to_markdown())


.. _sphx_glr_download_auto_examples_compare_classifiers.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: compare_classifiers.ipynb <compare_classifiers.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: compare_classifiers.py <compare_classifiers.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: compare_classifiers.zip <compare_classifiers.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
